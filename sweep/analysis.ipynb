{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "79dabc7c-da9d-43b5-8239-1ae5ad546526"
    }
   },
   "source": [
    "# Send rate and latency versus Link Load parameter\n",
    "\n",
    "This example experiment shows how to:\n",
    "\n",
    "* how to run POOSL models with replaced system parameters\n",
    "* collect the send rate and latency data from the POOSL simulations\n",
    "* plot the trend of send rate and latency versus Link Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "282b7c2e-b6d8-4b37-a54f-482da2e8bf6a"
    }
   },
   "outputs": [],
   "source": [
    "# import the convenience utility to run parameterized POOSL models\n",
    "import run_network_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "67ad3d56-fe23-4e28-8e30-2bedb37afcf9"
    }
   },
   "source": [
    "# Set up experiment\n",
    "The experiment needs to know certain parameters: such as the name of the topology, what values it should use for the default model parameters, as well as the experiment values (in this case the link load)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ad8c953e-2970-454f-a631-02f05d19a1bc"
    }
   },
   "outputs": [],
   "source": [
    "# set up the environment\n",
    "import numpy\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "def dict_product(value: dict):\n",
    "    return list(dict(zip(value.keys(), values)) for values in itertools.product(*value.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b9de78e3-f170-4c01-9fb9-6bcdfe3a06f6"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize template parameters, add different topologies here\n",
    "# 10 evenly spaced values between 0.05 and 0.95\n",
    "# NOTE: the output from linspace may show 0.50, but instead the real value is 0.4999994\n",
    "# Therefore, the literal 0.50 cannot be used to look up the data! Use\n",
    "# parameters[\"mesh\"][\"Load\"][2] or similar to look up the values instead.\n",
    "parameters = {\n",
    "    \"mesh\": {\n",
    "        \"Load\": numpy.linspace(0.05, 0.95, 10),\n",
    "        \"NIBufferCapacity\": [2],\n",
    "        \"SoC_type\": [\"Mesh_2x2\"],\n",
    "    },\n",
    "    \"bus\": {\n",
    "        \"Load\": numpy.linspace(0.05, 0.95, 10),\n",
    "        \"NIBufferCapacity\": [1, 4, 8, 16],\n",
    "        \"SoC_type\": [\"Bus_2_nodes\", \"Bus_4_nodes\", \"Bus_8_nodes\", \"Bus_16_nodes\", \"Bus_32_nodes\", \"Bus_64_nodes\"],\n",
    "    },\n",
    "    \"tree_buffers\": {\n",
    "        \"Load\": numpy.linspace(0.05, 0.95, 10),\n",
    "        \"NIBufferCapacity\": [1, 4, 8, 16],\n",
    "        \"SoC_type\": [\"NetworkFatTree3LayerDegree2\", \"NetworkFatTree3LayerDegree2\", \"NetworkFatTree3LayerDegree2\", \"NetworkFatTree3LayerDegree2\"],\n",
    "    },\n",
    "    \"tree_layers\": {\n",
    "        \"Load\": numpy.linspace(0.05, 0.95, 10),\n",
    "        \"NIBufferCapacity\": [4],\n",
    "        \"SoC_type\": [\"NetworkFatTree2LayerTest\"]\n",
    "        # , \"NetworkFatTree3LayerTest\", \"NetworkFatTree4LayerTest\", \"NetworkFatTree5LayerTest\"],\n",
    "    },\n",
    "    \"tree_degrees\": {\n",
    "        \"Load\": numpy.linspace(0.05, 0.95, 10),\n",
    "        \"NIBufferCapacity\": [1, 4, 8, 16],\n",
    "        \"SoC_type\": [\"NetworkFatTreeDegree5Terminals25\", \"NetworkFatTreeDegree4Terminals25\", \"NetworkFatTreeDegree3Terminals25\", \"NetworkFatTreeDegree2Terminals25\"],\n",
    "    },\n",
    "}\n",
    "parameters = dict(map(lambda x: (x[0], dict_product(x[1])), parameters.items()))\n",
    "\n",
    "# Change this line to the chosen topology\n",
    "# template_name = \"mesh\"\n",
    "template_name = \"bus\"\n",
    "# template_name = \"torus\"\n",
    "# template_name = \"tree\"\n",
    "# template_name = \"tree_layers\"\n",
    "# template_name = \"tree_buffers\"\n",
    "# template_name = \"tree_degrees\"\n",
    "\n",
    "output_directory_base = Path(f\"output/{template_name}\")\n",
    "selected_parameters = parameters[template_name]\n",
    "\n",
    "# Put the absolute path to your model here; do not forget to change \\ to / in the path on Windows\n",
    "model_path = Path(\"../model\").resolve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "03b1edfa-21a6-4aef-ac71-6e3e628fecf7"
    }
   },
   "source": [
    "## Run the parameterized models\n",
    "Now we execute one model for every `Load` value in our experiment. The `load_value` variable ranges from 0.05 to 0.95 in 4 steps. \n",
    "\n",
    "The log files are stored in separate output directories, as the output directory depends on the load parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c1607331-4e4f-4f7e-a295-eb95a42963eb"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def dir_from_params(params: dict) -> Path:\n",
    "    output_directory = output_directory_base\n",
    "    for val in map(lambda x: x[1], sorted(list(params.items()), key=lambda x: x[0])):\n",
    "        output_directory = output_directory / str(val)\n",
    "    return output_directory\n",
    "\n",
    "\n",
    "def get_all_params(model_parameters: dict):\n",
    "    return (\n",
    "        [model_path],\n",
    "        open(f\"templates/{template_name}_template.poosl\").read(),\n",
    "        model_parameters,\n",
    "        dir_from_params(model_parameters),\n",
    "    )\n",
    "\n",
    "\n",
    "all_params = list(map(get_all_params, selected_parameters))\n",
    "with Pool() as pool:\n",
    "    for (errcode, error), p, directory in tqdm(\n",
    "        pool.imap_unordered(run_network_model.run_network_model, all_params),\n",
    "        total=len(all_params),\n",
    "        desc=\"Evaluating all parameters\",\n",
    "    ):\n",
    "        if errcode != 0:\n",
    "            message = (\n",
    "                f\"Model with params {p} returned {errcode} and did not terminate to completion.\\n\"\n",
    "                f\"Check the output in {Path(directory).absolute()}\\nLast error was:\\n{error}\"\n",
    "            )\n",
    "            print(message)\n",
    "            raise Exception(message)\n",
    "\n",
    "print(\"Experiment finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1d2fcb2b-98ae-4b5f-b3ed-553cbac57f90"
    }
   },
   "source": [
    "## Define log file interpretation\n",
    "All the simulations are finished, and their output is stored in separate directories.\n",
    "We can now use those log files to fill the data tables (pandas DataFrames) by extracting the Point estimation data from the log files and inserting it into the table.\n",
    "\n",
    "The function `readLog` defines how to read the Point estimation value from a `.log` file.\n",
    "\n",
    "The last entry (i.e. the piece of text before the first tab) in the log file that can be converted to a Float will be used as the Point estimation for this log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "af7faba6-b6a1-454d-9bab-e24b784cb34e"
    }
   },
   "outputs": [],
   "source": [
    "def read_log(fname: Path):\n",
    "    if not fname.exists():\n",
    "        raise Exception(f'Unable to read log: \"{fname}\" does not exist!')\n",
    "\n",
    "    value = None\n",
    "    with open(fname) as log_file:\n",
    "        for line in log_file:\n",
    "            parts = line.split(\"\\t\")\n",
    "            try:\n",
    "                value = float(parts[0].strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "aa084048-cf9f-47b3-9929-8ad6558a7f34"
    }
   },
   "source": [
    "## Setup data tables\n",
    "Here, we set up two tables (pandas DataFrame) in which we will store the results. Initially, the results are all unset, but we will read the relevant log files to find the Point estimations for the send rate and the latency for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ad8c953e-2970-454f-a631-02f05d19a1bc"
    }
   },
   "outputs": [],
   "source": [
    "# set up the environment\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# prepare data structure\n",
    "raw_data = []\n",
    "model_indices = []\n",
    "for model_parameters in selected_parameters:\n",
    "    # dict iteration is random so we save the indexes in order that we encounter them\n",
    "    model_indices.append(model_parameters)\n",
    "    output_directory = dir_from_params(model_parameters)\n",
    "\n",
    "    # Load all the latency and sendrate log files\n",
    "    data_dict = {}\n",
    "    for file in output_directory.glob(\"*.log\"):\n",
    "        pattern = r\"([a-zA-Z]+)(\\d+)\"\n",
    "        m = re.match(pattern, file.stem)\n",
    "        if not m:\n",
    "            continue\n",
    "        data_dict[(m.group(1), m.group(2))] = read_log(file)\n",
    "    raw_data.append(data_dict)\n",
    "\n",
    "# Prepare pandas DataFrame\n",
    "model_indices = pd.MultiIndex.from_frame(pd.DataFrame(model_indices)).reorder_levels([2, 1, 0])\n",
    "data = pd.DataFrame(data=raw_data, index=model_indices)\n",
    "data = data.reindex(sorted(data.columns), axis=1).sort_index()\n",
    "data.columns = pd.MultiIndex.from_tuples(data.columns, names=[\"Type\", \"Node\"])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8adf9bbe-0b91-4612-bb5a-96eb3124a4e4"
    }
   },
   "source": [
    "## Post-process and plot outcomes\n",
    "\n",
    "We can apply all kinds of interesting post-processing on the tables, and plot some of the results.\n",
    "\n",
    "The figures can be exported as png, pdf, ps, eps, svg, and pgf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1e3a4238-3a7f-40b9-9c31-31af9a537b82"
    }
   },
   "outputs": [],
   "source": [
    "# compute the row-average of the Latency columns, and add it to the table\n",
    "data[\"Latency\", \"average\"] = data[\"Latency\"].mean(axis=1)\n",
    "data[\"SendRate\", \"average\"] = data[\"SendRate\"].mean(axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "316ce978-dfd7-43c8-8362-4e52148f217e"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot') # select the ggplot style\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8451d16e-72f3-4fce-aad0-aa446b0706a8"
    }
   },
   "outputs": [],
   "source": [
    "pdf = PdfPages(output_directory_base / 'graphs.pdf') # Open a file to write different graphs to; don't forget to close the PDF later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a10b1ba2-15e5-49c3-a250-4d3eceb3d0e8"
    }
   },
   "outputs": [],
   "source": [
    "# convenience function to create line plots in a single line, with some convenient default values\n",
    "def line_plot(df, title, xlabel, ylabel, pdf=None):\n",
    "    fig = df.plot.line(title=title, marker='s', figsize=(10,7))\n",
    "    # use the line below instead on older versions if the margins are off\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if pdf is not None:\n",
    "        pdf.savefig()\n",
    "    return fig\n",
    "\n",
    "# Because experiments can have different number of nodes, we only the load values of the current experiment\n",
    "# this function is better combined with a call to groubpy to the dataframe with all the data\n",
    "def extract_df(df):\n",
    "    return df.droplevel([0, 1]).dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "0d6c536a-c387-4d7a-93b4-f6012e04f654"
    }
   },
   "outputs": [],
   "source": [
    "# plot line graphs for each buffer experiment with different load values\n",
    "for group, df in data[\"SendRate\"].groupby(level=[0,1]):\n",
    "    line_plot(extract_df(df), \n",
    "        f\"Send rate with varying link load\\nmodel = {group[0]}, buffer size = {group[1]}\", \n",
    "        'Link load', 'Send rate [flits/time unit]', pdf)\n",
    "    plt.show()\n",
    "for group, df in data[\"Latency\"].groupby(level=[0,1]):\n",
    "    line_plot(extract_df(df), \n",
    "        f\"Latency with varying link load\\nmodel = {group[0]}, buffer size = {group[1]}\", \n",
    "        'Link load', 'Latency [time unit]', pdf)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "52b06710-dd7d-4807-815d-742100f95619"
    }
   },
   "source": [
    "# Plot a subset of the results\n",
    "You can easily filter out some of the columns, like shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "872b5494-e937-4950-972f-4955e1004aa3"
    }
   },
   "outputs": [],
   "source": [
    "# extract only the rows for which the index correspondes to the first buffer value\n",
    "latency12_df = data.loc[\"Bus_4_nodes\", 1][\"Latency\"][[\"1\", \"2\"]] # select only the Latency1 and Latency2 columns\n",
    "line_plot(latency12_df, \"Link load for Node 1 and 2\", 'Link load', 'Latency [time units]', pdf)\n",
    "plt.show()\n",
    "\n",
    "# Buffer size  1 2 4 8 16 \n",
    "# Network size 2 4 8 16 32 64\n",
    "# Latency\n",
    "# Send Rate\n",
    "# Link load 0.05, 0.15, 9.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\n",
    "\n",
    "\n",
    "# Show send rate for 0.05 for buffer size 4 and network 1 2 4 8 16\n",
    "# Show send rate for 0.25 for buffer size 4 and network 1 2 4 8 16\n",
    "# Show send rate for 0.45 for buffer size 4 and network 1 2 4 8 16\n",
    "# Show send rate for 0.95 for buffer size 4 and network 1 2 4 8 16\n",
    "# Show latency for 0.05 for buffer size 4 and network 1 2 4 8 16\n",
    "# Show latency for 0.25 for buffer size 4 and network 1 2 4 8 16\n",
    "# Show latency for 0.45 for buffer size 4 and network 1 2 4 8 16\n",
    "# Show latency for 0.95 for buffer size 4 and network 1 2 4 8 16\n",
    "for dataType in [\"Latency\", \"SendRate\"]:\n",
    "    for link in [\"0.05\", \"0.25\", \"0.45\", \"0.95\"]:\n",
    "        plotData = pd.DataFrame()\n",
    "        for network in [\"Bus_1_nodes\", \"Bus_2_nodes\", \"Bus_4_nodes\", \"Bus_8_nodes\", \"Bus_16_nodes\"]:\n",
    "            plotData.add(data.loc[network, 1][dataType][[\"average\"]])\n",
    "                        \n",
    "        line_plot(plotData, f\"Latency of several networks at load {link}\", 'Link load', 'Latency [time units]', pdf)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    df.droplevel([0, 1]).dropna(axis=1, how='all')\n",
    "\n",
    "for group, df in data[\"SendRate\"].groupby(level=[0,1]):\n",
    "    line_plot(extract_df(df), \n",
    "        f\"Send rate with varying link load\\nmodel = {group[0]}, buffer size = {group[1]}\", \n",
    "        'Link load', 'Send rate [flits/time unit]', pdf)\n",
    "    plt.show()\n",
    "\n",
    "# Show send rate for 0.05 for buffer size 1 8 16 and network 2 16 and 64\n",
    "# Show send rate for 0.55 for buffer size 1 8 16 and network 2 16 and 64\n",
    "# Show send rate for 0.95 for buffer size 1 8 16 and network 2 16 and 64\n",
    "# Show latency for 0.05 for buffer size 1 8 16 and network 2 16 and 64\n",
    "# Show latency for 0.55 for buffer size 1 8 16 and network 2 16 and 64\n",
    "# Show latency for 0.95 for buffer size 1 8 16 and network 2 16 and 64\n",
    "plotData = pd.DataFrame()\n",
    "for dataType in [\"Latency\", \"SendRate\"]:\n",
    "    for link in [\"0.05\", \"0.25\", \"0.45\", \"0.95\"]:\n",
    "        for network in [\"Bus_1_nodes\", \"Bus_2_nodes\", \"Bus_4_nodes\", \"Bus_8_nodes\", \"Bus_16_nodes\"]:\n",
    "            line_plot(data.loc[network, 1][dataType][[\"average\"]])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "79653d6f-efd1-49e2-8277-964809184ce9"
    }
   },
   "source": [
    "## Save results for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fdc38dd9-7de8-484b-8d33-047c811f3fe1"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(output_directory_base / \"data.csv\")\n",
    "# load back into dataframe by using: df = pandas.read_csv('data.csv', index_col=[0,1,2], header=[0,1])\n",
    "\n",
    "if pdf != None:\n",
    "    pdf.close()\n",
    "pdf = None  # remove the reference to the multipage PDF\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
